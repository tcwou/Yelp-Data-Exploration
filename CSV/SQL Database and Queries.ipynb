{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Open Dataset Visualization\n",
    "\n",
    "The aim of the project is to visualize the data contained in the [Yelp open dataset](https://www.yelp.com/dataset). The dataset was converted from JSON format into a SQLite database for efficient querying of the 8.4GB dataset. The output from the SQL queries were brought into python for visualization.\n",
    "\n",
    "The final size of the SQL database is 6.3GB, consisting of 192,609 rows in the business table, 1,637,138 rows in the users table and 6,685,900 rows in the review table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLite Database Creation\n",
    "\n",
    "The dataset provided by yelp was split into six JSON files:\n",
    "\n",
    "\n",
    "| File          | Description                           | File Size (kb) |\n",
    "|---------------|---------------------------------------|----------------|\n",
    "| business.json | Business location data and attributes | 138,279,749    |\n",
    "| checkin.json  | User 'Checkins' to businesses         | 408,807,658    |\n",
    "| photo.json    | Photo data for businesses             | 25,661,152     |\n",
    "| review.json   | User reviews of businesses            | 5,347,475,638  |\n",
    "| tip.json      | User tips of businesses               | 244,535,478    |\n",
    "| user.json     | User information                      | 2,485,747,393  |\n",
    "\n",
    "Due to the large file sizes, converting the data from JSON format into a SQL database will allow us to query the data without worrying about memory limitations. We will process only the business, review and user files for the purposes of this project.\n",
    "\n",
    "The documentation for the JSON files can be found [here](https://www.yelp.com/dataset/documentation/main). Exploring the 'business.json' documentation and data reveals three attributes - \"attributes\", \"categories\" and \"hours\" - that have value branches more than one layer deep. Simply flattening these values as a single entry will lead to multiple values in a field, violating the rules of database normalization. Thus, for these attributes separate category tables will be created to list out each possible value and preventing multiple entries. The new tables created are:\n",
    "\n",
    "\"parking\" - parking options available at the business  \n",
    "\n",
    "\"meal\" - meal options serviced by the restaurant e.g. lunch, dinner, dessert  \n",
    "\n",
    "\"hours\" - opening and closing hours for all seven days of the week  \n",
    "\n",
    "\"ambience\" - the ambience of the business e.g. romantic, casual, formal  \n",
    "\n",
    "\"category\" - category of the business e.g. restaurants, French, coffee  \n",
    "\n",
    "\"misc\" - all other attributes that do are not covered in other tables  \n",
    "\n",
    "\n",
    "business.json contains a 'business_id' field that is unique to each entry, thus we will use this as the primary key for the business table. A similar id field can be found for the review.json and user.json files. Thus the final schema is shown below.\n",
    "\n",
    "<img src=\"SQL Schema Yelp.svg\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries\n",
    "\n",
    "The following queries were used to generate the CSV files used in the [data visualization](https://github.com/tcwou/Yelp-Data-Exploration/blob/master/Data%20Visualization.ipynb) and [sentiment analysis](https://github.com/tcwou/Yelp-Data-Exploration/blob/master/Sentiment%20Analysis.ipynb) portions of this project, the first five rows of each query is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0   1          2           3      4         5\n",
      "0    Toronto  ON  43.681084  -79.392410  10071  3.465892\n",
      "1  Las Vegas  NV  36.128933 -115.192815   8266  3.504658\n",
      "2    Phoenix  AZ  33.518598 -112.063534   5103  3.484617\n",
      "3   Montr√©al  QC  45.512597  -73.587750   4508  3.734028\n",
      "4    Calgary  AB  51.040238 -114.069034   3674  3.509662\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# City, state, latitude, longitude, no of businesses, no of reviews, cities ordered by most restaurants/eateries\n",
    "\"\"\" SELECT city, state, latitude, longitude, COUNT(business_id), AVG(stars) \n",
    "        FROM\n",
    "        (SELECT city, state, b.business_id, stars\n",
    "        FROM business b\n",
    "        JOIN category c ON c.business_id = b.business_id\n",
    "        WHERE c.food = 1\n",
    "        GROUP BY b.business_id) \n",
    "        GROUP BY city ORDER BY COUNT(business_id) DESC\"\"\"\n",
    "\n",
    "print(pd.read_csv('topcities.csv', header=None).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0        1           2         3           4\n",
      "0  0  5338376   41.756468  3.707804  536.649918\n",
      "1  1   327058  171.620813  3.878414  761.444514\n",
      "2  2   279978  251.512180  3.851132  816.692208\n",
      "3  3   193766  301.043491  3.821575  863.226010\n",
      "4  4   135946  437.617650  3.792993  908.563290\n"
     ]
    }
   ],
   "source": [
    "# Number of users, Average no of review, rating, review length; grouped by number of year of elite\n",
    "\"\"\" SELECT elite, COUNT(*), AVG(review_count), AVG(average_stars), AVG(LENGTH(text))\n",
    "        FROM review JOIN user ON user.user_id = review.user_id GROUP BY elite \"\"\"\n",
    "\n",
    "print(pd.read_csv('elite.csv', header=None).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0       1        2       3       4\n",
      "0   2004      81       13     NaN     NaN\n",
      "1   2005    1001      876  1135.0  6638.0\n",
      "2   2006    5836     5081   483.0   480.0\n",
      "3   2007   16480    21389   182.0   320.0\n",
      "4   2008   32544    57347    97.0   168.0\n",
      "5   2009   63977   101173    96.0    76.0\n",
      "6   2010  106840   187387    66.0    85.0\n",
      "7   2011  168467   302867    57.0    61.0\n",
      "8   2012  182900   367090     8.0    21.0\n",
      "9   2013  197220   491294     7.0    33.0\n",
      "10  2014  225437   704862    14.0    43.0\n",
      "11  2015  238660   952400     5.0    35.0\n",
      "12  2016  199148  1098786   -16.0    15.0\n",
      "13  2017  120531  1217673   -39.0    10.0\n",
      "14  2018   78016  1177662   -35.0    -3.0\n"
     ]
    }
   ],
   "source": [
    "# Get yearly growth of users and reviews\n",
    "\n",
    "\"\"\" \n",
    "WITH \n",
    "year_new_users as (\n",
    "SELECT strftime('%Y', yelping_since) year, COUNT(*) new_users\n",
    "FROM user GROUP BY 1\n",
    "),\n",
    "prev_year_new_users as (\n",
    "SELECT *,\n",
    "lag(new_users) OVER (ORDER BY year) AS prev_new_users\n",
    "FROM year_new_users\n",
    "),\n",
    "year_new_reviews as (\n",
    "SELECT strftime('%Y', date) year, COUNT(*) new_reviews\n",
    "FROM review GROUP BY 1\n",
    "),\n",
    "prev_year_new_reviews as (\n",
    "SELECT *,\n",
    "lag(new_reviews) OVER (ORDER BY year) AS prev_new_reviews\n",
    "FROM year_new_reviews\n",
    ")\n",
    "\n",
    "SELECT r.year, new_users, new_reviews,\n",
    "round(100*(new_users-prev_new_users)/prev_new_users,1) as user_growth,\n",
    "round(100*(new_reviews-prev_new_reviews)/prev_new_reviews,1) as review_growth\n",
    "FROM prev_year_new_users u\n",
    "JOIN prev_year_new_reviews r ON r.year = u.year\n",
    "ORDER BY 1\n",
    "\"\"\"\n",
    "print(pd.read_csv('year_growth.csv', header=None, index_col=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       0    1   2   \\\n",
      "0  b2jN2mm9Wf3RcrZCgfo1cg  4.0   0   \n",
      "1  FxLfqxdYPA6Z85PFKaqLrg  2.0   0   \n",
      "2  AakkkTuGZA2KBodKi2_u8A  3.5   1   \n",
      "3  d_L-rfS1vT3JMzgCUGtiow  4.0   1   \n",
      "4  3JxKzWquEbPC3yPIfoCiLw  4.0   1   \n",
      "\n",
      "                                                  3   \\\n",
      "0  Breweries, Event Planning & Services, Pubs, Di...   \n",
      "1                        Italian, Salad, Gluten-Free   \n",
      "2                           Asian Fusion, Vietnamese   \n",
      "3    Breakfast & Brunch, Tapas/Small Plates, Mexican   \n",
      "4                                       Asian Fusion   \n",
      "\n",
      "                                                  4   5   6   7   8   \\\n",
      "0  I was really looking forward to visiting after...   1   0   0   2   \n",
      "1  Wow. So surprised at the one and two star revi...   0   0   0   4   \n",
      "2  I cannot believe how things have changed in 3 ...   1   1   0   1   \n",
      "3  Pick any meat on the planet and the chef will ...   0   0   0   5   \n",
      "4  Best chinese resto. Highly recommended. 5 star...   0   0   0   5   \n",
      "\n",
      "                       9   10  \n",
      "0  sG_h0dIzTKWa3Q6fmb4u-g   0  \n",
      "1  GYNnVehQeXjty0xH7-6Fhw   0  \n",
      "2  TpyOT5E16YASd7EWjLQlrw   1  \n",
      "3  2mxBNBeFrgDszqGS5tdEHA   0  \n",
      "4  uFVAAe0JC81IPmxgT49Hcw   0  \n"
     ]
    }
   ],
   "source": [
    "# Get 35,000 random restaurant reviews\n",
    "\n",
    "\"\"\" \n",
    "SELECT b_id, b_stars, is_open, cats, text, r.useful, r.funny, r.cool, r.stars, u.user_id, u.elite\n",
    "FROM (SELECT b.business_id b_id, AVG(stars) b_stars, is_open, group_concat(category, \", \") cats\n",
    "FROM business b\n",
    "JOIN category c ON b.business_id = c.business_id\n",
    "WHERE c.food = 1 AND b_id IN (SELECT business_id FROM business ORDER BY RANDOM() LIMIT 35000)\n",
    "GROUP BY b.business_id)\n",
    "JOIN review r ON r.business_id = b_id\n",
    "JOIN user u ON u.user_id = r.user_id\n",
    "LIMIT 35000\n",
    "\"\"\"\n",
    "\n",
    "print(pd.read_csv('35k_reviews.csv', header=None).head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
